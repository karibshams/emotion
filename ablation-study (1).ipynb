{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"86c4cfcd30b0462cbaef73f91e7398e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45204915d64e4c2aab18a26e0a1d6c47","IPY_MODEL_b32a86470cf542e6b2c280b7f09d874b","IPY_MODEL_16fc3a3b97c446198c1bd1e37ce86c51"],"layout":"IPY_MODEL_d39e6a6dc58f454594e6d803d7bef024"}},"45204915d64e4c2aab18a26e0a1d6c47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07a61f30d11a4703afbb327c309de4ac","placeholder":"​","style":"IPY_MODEL_ddb654b094db42598035406504d4b70e","value":"tokenizer_config.json: 100%"}},"b32a86470cf542e6b2c280b7f09d874b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea4cb722a8ca45648939d6a562535553","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5b053493b449493584b63e8ee2251ddb","value":25}},"16fc3a3b97c446198c1bd1e37ce86c51":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50a57541580e48eeb2c923f94e3be232","placeholder":"​","style":"IPY_MODEL_dea8af2af6494580a8e1f5e56096f661","value":" 25.0/25.0 [00:00&lt;00:00, 807B/s]"}},"d39e6a6dc58f454594e6d803d7bef024":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07a61f30d11a4703afbb327c309de4ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddb654b094db42598035406504d4b70e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea4cb722a8ca45648939d6a562535553":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b053493b449493584b63e8ee2251ddb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50a57541580e48eeb2c923f94e3be232":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dea8af2af6494580a8e1f5e56096f661":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e00b7cbcf2d4feaa39e643b496c6954":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fcf6b132bf064ecc86120892a9394d96","IPY_MODEL_bd7295e1914c4d989e325bedb090ea57","IPY_MODEL_1cfe92b35c364df0b6af2adba30aaa9d"],"layout":"IPY_MODEL_e563abf663364675af26aa8a80318fdd"}},"fcf6b132bf064ecc86120892a9394d96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bac085bb5c7d45c8acc36b02de5d0ff0","placeholder":"​","style":"IPY_MODEL_2c9d6937cd8c4158b27c84ab98aab81a","value":"config.json: 100%"}},"bd7295e1914c4d989e325bedb090ea57":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eaaa4d117b6942ceace411d5bfafeb10","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e2cfce433f240c383f2757b772ba067","value":481}},"1cfe92b35c364df0b6af2adba30aaa9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5affc2425234e36ab27de4cc26b6f68","placeholder":"​","style":"IPY_MODEL_8ce2a5e567664812bd89be5f1cd1d083","value":" 481/481 [00:00&lt;00:00, 35.5kB/s]"}},"e563abf663364675af26aa8a80318fdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bac085bb5c7d45c8acc36b02de5d0ff0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c9d6937cd8c4158b27c84ab98aab81a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eaaa4d117b6942ceace411d5bfafeb10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e2cfce433f240c383f2757b772ba067":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d5affc2425234e36ab27de4cc26b6f68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ce2a5e567664812bd89be5f1cd1d083":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea13bde96e3c487f835fa082a821c06b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b10d9990874f47a9bc81b34e83a5f5c2","IPY_MODEL_368ada7785a142409ac40dc79e560876","IPY_MODEL_e01b406082e24fe0a4f4d42e43d780d5"],"layout":"IPY_MODEL_7a8310272df84fe7b094c6afeb80c977"}},"b10d9990874f47a9bc81b34e83a5f5c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_056ff042a6424632b74e2c21f6fde9f8","placeholder":"​","style":"IPY_MODEL_76acb4add0f24dc9bf93807079e7540d","value":"vocab.json: 100%"}},"368ada7785a142409ac40dc79e560876":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_802536ca161848d9bf028aef0cdda9c0","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a8ee0bf805f448828bdfc6d75a3c9053","value":898823}},"e01b406082e24fe0a4f4d42e43d780d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c233d2dc16a745f8800aa0216a525904","placeholder":"​","style":"IPY_MODEL_9f04b3b5a2e2490cbdfd33b6756bee12","value":" 899k/899k [00:00&lt;00:00, 4.74MB/s]"}},"7a8310272df84fe7b094c6afeb80c977":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"056ff042a6424632b74e2c21f6fde9f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76acb4add0f24dc9bf93807079e7540d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"802536ca161848d9bf028aef0cdda9c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8ee0bf805f448828bdfc6d75a3c9053":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c233d2dc16a745f8800aa0216a525904":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f04b3b5a2e2490cbdfd33b6756bee12":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e8d7f7c43e24752ac79cd1d5794b036":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_49ec49701a1c4c4cbd1e464e1549acc7","IPY_MODEL_dbe9c71516c1448a83994e74e7d96091","IPY_MODEL_462d22f82dd9495f80225756e8b439e5"],"layout":"IPY_MODEL_d9d47d7a00f6402e93c8f5989a2d9610"}},"49ec49701a1c4c4cbd1e464e1549acc7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea9a2053d7bd474fbcee61f52f7ebbd1","placeholder":"​","style":"IPY_MODEL_ede088e6a2334edd82a415731753804b","value":"merges.txt: 100%"}},"dbe9c71516c1448a83994e74e7d96091":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_91880d987d2449558da7697be20da8a6","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0c77709c7a84cfcac488feebe1b57ba","value":456318}},"462d22f82dd9495f80225756e8b439e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_374420054d6841439acbd0d6ec881600","placeholder":"​","style":"IPY_MODEL_7e2f09fc20bf4f0b89288e5a80e6b0ce","value":" 456k/456k [00:00&lt;00:00, 3.67MB/s]"}},"d9d47d7a00f6402e93c8f5989a2d9610":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea9a2053d7bd474fbcee61f52f7ebbd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ede088e6a2334edd82a415731753804b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91880d987d2449558da7697be20da8a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0c77709c7a84cfcac488feebe1b57ba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"374420054d6841439acbd0d6ec881600":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e2f09fc20bf4f0b89288e5a80e6b0ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55b58814329e488a971f0b01f3ce68fb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_df1f5799e36241ca835fa6f72d677f24","IPY_MODEL_d54250dd903a444a8c2f82965bbf3f40","IPY_MODEL_bfdb8d49c7da431091e6093ce5fb2059"],"layout":"IPY_MODEL_05cefcce364742bc970f2a8e22c1385f"}},"df1f5799e36241ca835fa6f72d677f24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ac518fbfe8a46f3aa1b58d49f18be40","placeholder":"​","style":"IPY_MODEL_c4516c898b7f4a9ea23f2bcaae2f1529","value":"tokenizer.json: 100%"}},"d54250dd903a444a8c2f82965bbf3f40":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ed92fa5a7db431e8f7e8b80ba0d66ca","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d1410eb435f442a2abdfcc2fd7c104f8","value":1355863}},"bfdb8d49c7da431091e6093ce5fb2059":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffedd523afbb46249ed420c5f364bb3b","placeholder":"​","style":"IPY_MODEL_7007db6848b74974a639ce52da7adeea","value":" 1.36M/1.36M [00:00&lt;00:00, 10.5MB/s]"}},"05cefcce364742bc970f2a8e22c1385f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ac518fbfe8a46f3aa1b58d49f18be40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4516c898b7f4a9ea23f2bcaae2f1529":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ed92fa5a7db431e8f7e8b80ba0d66ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1410eb435f442a2abdfcc2fd7c104f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ffedd523afbb46249ed420c5f364bb3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7007db6848b74974a639ce52da7adeea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3078a02a6ff9481d9d16994deae3ebf1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e0e6f7e3226b4d84baa8876243d6c677","IPY_MODEL_4386557399cc4eff89489f99c1d0abfc","IPY_MODEL_ed1e69799bc04b56931c0f15b1d5bcb5"],"layout":"IPY_MODEL_1c3600b91fac4a23962afa41c57bcbc7"}},"e0e6f7e3226b4d84baa8876243d6c677":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_353a47760e31432d9e693cbeea2c463f","placeholder":"​","style":"IPY_MODEL_9c489bf282a040bf8b3fa5a85da99103","value":"model.safetensors: 100%"}},"4386557399cc4eff89489f99c1d0abfc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eacba2a4b0aa43e6b98912e0211b515c","max":498818054,"min":0,"orientation":"horizontal","style":"IPY_MODEL_65a8922b0e814c1e886bb754606cd342","value":498818054}},"ed1e69799bc04b56931c0f15b1d5bcb5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b143480a90a4599adf1eb7b0bdc2497","placeholder":"​","style":"IPY_MODEL_872d8e8fb5924f4eb07629d4fe0158c5","value":" 499M/499M [00:05&lt;00:00, 62.1MB/s]"}},"1c3600b91fac4a23962afa41c57bcbc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"353a47760e31432d9e693cbeea2c463f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c489bf282a040bf8b3fa5a85da99103":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eacba2a4b0aa43e6b98912e0211b515c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65a8922b0e814c1e886bb754606cd342":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0b143480a90a4599adf1eb7b0bdc2497":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"872d8e8fb5924f4eb07629d4fe0158c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11056502,"sourceType":"datasetVersion","datasetId":6888457},{"sourceId":11057314,"sourceType":"datasetVersion","datasetId":6889051}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom tqdm import tqdm","metadata":{"id":"h2RyKdQQ8J1w","trusted":true,"execution":{"iopub.status.busy":"2025-03-19T14:18:51.302026Z","iopub.execute_input":"2025-03-19T14:18:51.302400Z","iopub.status.idle":"2025-03-19T14:18:59.375295Z","shell.execute_reply.started":"2025-03-19T14:18:51.302366Z","shell.execute_reply":"2025-03-19T14:18:59.374271Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"file_path = '/kaggle/input/balance/balanced_dataset.csv'\ndf = pd.read_csv(file_path)\n\ndf[\"text\"] = (\n    df[\"Product Name\"] + \" [SEP] \" +\n    df[\"Rating\"].astype(str) + \" [SEP] \" +\n    df[\"Review\"] + \" [SEP] \" +\n    df[\"Product Category\"] + \" [SEP] \" +\n    df[\"Data Source\"] + \" [SEP] \" +\n    df[\"Sentiment\"]\n)\n\ncolumns_to_remove = ['Rating', 'Product Name', 'Product Category', 'Data Source', 'Review', 'Sentiment']\ndf = df.drop(columns=columns_to_remove)\n\ndef preprocess_data(df, tokenizer, max_length=128):\n    def encode_emotion(emotion):\n        emotion_mapping = {\"Happy\": 0, \"Love\": 1, \"Sadness\": 2, \"Anger\": 3, \"Fear\": 4}\n        return emotion_mapping[emotion]\n\n    df['label'] = df['Emotion'].apply(encode_emotion)\n    tokenized_data = tokenizer(df['text'].tolist(), padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n\n    return tokenized_data['input_ids'], tokenized_data['attention_mask'], torch.tensor(df['label'].values)","metadata":{"id":"gVzsC45g8NgU","trusted":true,"execution":{"iopub.status.busy":"2025-03-19T14:19:02.782420Z","iopub.execute_input":"2025-03-19T14:19:02.783020Z","iopub.status.idle":"2025-03-19T14:19:03.445784Z","shell.execute_reply.started":"2025-03-19T14:19:02.782980Z","shell.execute_reply":"2025-03-19T14:19:03.444879Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Define Multi-Head Polynomial Attention\nclass MultiHeadPolynomialAttention(nn.Module):\n    def __init__(self, poly_degree=2, num_heads=8, hidden_dim=768):\n        super(MultiHeadPolynomialAttention, self).__init__()\n        self.num_heads = num_heads\n        self.poly_degree = poly_degree\n        self.hidden_dim = hidden_dim\n        self.head_dim = hidden_dim // num_heads\n\n        assert hidden_dim % num_heads == 0, \"Hidden dim must be divisible by num_heads\"\n\n        self.query = nn.Linear(hidden_dim, hidden_dim)\n        self.key = nn.Linear(hidden_dim, hidden_dim)\n        self.value = nn.Linear(hidden_dim, hidden_dim)\n        self.output = nn.Linear(hidden_dim, hidden_dim)\n\n    def forward(self, query, key, value, mask=None):\n        batch_size = query.size(0)\n        query = self.query(query).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n        key = self.key(key).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n        value = self.value(value).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n        attention_scores = torch.matmul(query, key.transpose(-1, -2)) / (self.head_dim ** 0.5)\n        attention_scores = attention_scores ** self.poly_degree\n\n        if mask is not None:\n            mask = mask.unsqueeze(1).unsqueeze(2)\n            attention_scores = attention_scores.masked_fill(mask == 0, float('-inf'))\n\n        attention_weights = torch.softmax(attention_scores, dim=-1)\n        attention_output = torch.matmul(attention_weights, value)\n        attention_output = attention_output.transpose(1, 2).contiguous().view(batch_size, -1, self.hidden_dim)\n        return self.output(attention_output)","metadata":{"id":"P5I-IhOxMNdD","trusted":true,"execution":{"iopub.status.busy":"2025-03-19T14:20:05.038095Z","iopub.execute_input":"2025-03-19T14:20:05.038507Z","iopub.status.idle":"2025-03-19T14:20:05.048969Z","shell.execute_reply.started":"2025-03-19T14:20:05.038473Z","shell.execute_reply":"2025-03-19T14:20:05.048002Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Add Mixout class\nclass Mixout(nn.Module):\n    def __init__(self, target, p=0.9):\n        super().__init__()\n        if not 0 <= p <= 1:\n            raise ValueError(f\"Mixout probability must be in [0, 1], got {p}\")\n        self.p = p\n        self.target = target\n        self.keep_mask = None\n\n    def forward(self, input):\n        if self.p == 0 or not self.training:\n            return input\n        if self.p == 1:\n            return self.target\n        if self.keep_mask is None or self.keep_mask.size() != input.size():\n            self.keep_mask = torch.bernoulli((1 - self.p) * torch.ones_like(input)).to(input.device)\n        mask = self.keep_mask\n        return (mask * input + (1 - mask) * self.target) / (1 - self.p)","metadata":{"id":"mLBZl80zLPLe","trusted":true,"execution":{"iopub.status.busy":"2025-03-19T14:20:11.341314Z","iopub.execute_input":"2025-03-19T14:20:11.341584Z","iopub.status.idle":"2025-03-19T14:20:11.346961Z","shell.execute_reply.started":"2025-03-19T14:20:11.341563Z","shell.execute_reply":"2025-03-19T14:20:11.346188Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class EmotionModel(nn.Module):\n    def __init__(self, base_model_name, use_poly_attention=False, use_swa=False, use_mixout=False, use_lora=False, use_bitfit=False, use_reft=False):\n        super().__init__()\n        self.base_model = AutoModel.from_pretrained(base_model_name)\n        self.hidden_dim = self.base_model.config.hidden_size\n        self.use_lora = use_lora\n        self.use_bitfit = use_bitfit\n        self.use_reft = use_reft\n        self.use_mixout = use_mixout\n        self.use_poly_attention = use_poly_attention\n\n        self.is_modernbert = \"answerdotai/ModernBERT-base\" in base_model_name\n\n        if use_poly_attention:\n            self.poly_attention = MultiHeadPolynomialAttention(poly_degree=2, num_heads=8,\n                                                               hidden_dim=self.hidden_dim)\n\n        if self.use_mixout:\n            self.apply_mixout(self.base_model)\n\n        if self.use_lora:\n            self.lora_layer = nn.Linear(self.hidden_dim, self.hidden_dim)\n\n        if self.use_bitfit:\n            self.bitfit_bias = nn.Parameter(torch.zeros(self.hidden_dim))\n\n        if self.use_reft:\n            self.reft_layer = nn.Linear(self.hidden_dim, self.hidden_dim)\n\n        self.fc_combined = nn.Linear(self.hidden_dim, 256)\n        self.fc_output = nn.Linear(256, 5)\n\n    def apply_mixout(self, module, p=0.1):\n        for name, child in module.named_children():\n            if isinstance(child, nn.Linear):\n                target_state_dict = child.state_dict()\n                mixout_layer = nn.Linear(child.in_features, child.out_features)\n                mixout_layer.weight = nn.Parameter(\n                    Mixout(target_state_dict['weight'], p=p)(child.weight)\n                )\n                if child.bias is not None:\n                    mixout_layer.bias = child.bias\n                setattr(module, name, mixout_layer)\n            else:\n                self.apply_mixout(child, p=p)\n\n    def forward(self, input_ids, attention_mask):\n        base_output = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = base_output.last_hidden_state[:, 0, :] if self.is_modernbert else base_output.pooler_output\n        last_hidden_state = base_output.last_hidden_state\n\n        if self.use_poly_attention:\n            attention_output = self.poly_attention(last_hidden_state, last_hidden_state, last_hidden_state,\n                                                   mask=attention_mask)\n        if self.use_lora:\n            pooled_output = self.lora_layer(pooled_output)\n\n        if self.use_bitfit:\n            pooled_output = pooled_output + self.bitfit_bias\n\n        if self.use_reft:\n            pooled_output = self.reft_layer(pooled_output)\n\n        x = F.relu(self.fc_combined(pooled_output))\n        return self.fc_output(x)\n","metadata":{"id":"PwJZmvuv8NZU","trusted":true,"execution":{"iopub.status.busy":"2025-03-19T14:20:14.241300Z","iopub.execute_input":"2025-03-19T14:20:14.241573Z","iopub.status.idle":"2025-03-19T14:20:14.250991Z","shell.execute_reply.started":"2025-03-19T14:20:14.241553Z","shell.execute_reply":"2025-03-19T14:20:14.249917Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def train_model(model, dataloader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    for input_ids, attention_masks, labels in dataloader:\n        input_ids, attention_masks, labels = input_ids.to(device), attention_masks.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask=attention_masks)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(dataloader)\n\ndef evaluate_model(model, dataloader, device):\n    model.eval()\n    total_loss = 0\n    all_preds, all_labels = [], []\n    criterion = nn.CrossEntropyLoss()\n    with torch.no_grad():\n        for input_ids, attention_masks, labels in dataloader:\n            input_ids, attention_masks, labels = input_ids.to(device), attention_masks.to(device), labels.to(device)\n            outputs = model(input_ids, attention_mask=attention_masks)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().numpy())\n    return total_loss / len(dataloader), all_preds, all_labels\n","metadata":{"id":"Jw5W-RUl_BhK","trusted":true,"execution":{"iopub.status.busy":"2025-03-19T14:20:19.753119Z","iopub.execute_input":"2025-03-19T14:20:19.753396Z","iopub.status.idle":"2025-03-19T14:20:19.760184Z","shell.execute_reply.started":"2025-03-19T14:20:19.753375Z","shell.execute_reply":"2025-03-19T14:20:19.759225Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Model selection\nbase_models = [\n    \"bert-base-multilingual-uncased\",\n    \"roberta-base\",\n    \"xlm-roberta-base\",\n    \"answerdotai/ModernBERT-base\"\n]\n\n# Full configurations with additional techniques\nconfigurations = [\n    {\"use_poly_attention\": False, \"use_mixout\": False, \"use_lora\": False, \"use_bitfit\": False, \"use_reft\": False},\n    {\"use_poly_attention\": True, \"use_mixout\": False, \"use_lora\": True, \"use_bitfit\": False, \"use_reft\": True},\n    {\"use_poly_attention\": True, \"use_mixout\": True, \"use_lora\": True, \"use_bitfit\": False, \"use_reft\": False},\n    {\"use_poly_attention\": False, \"use_mixout\": True, \"use_lora\": True, \"use_bitfit\": True, \"use_reft\": True},\n    {\"use_poly_attention\": True, \"use_mixout\": True, \"use_lora\": True, \"use_bitfit\": True, \"use_reft\": True}\n]","metadata":{"id":"YDnz0Gks8NWG","trusted":true,"execution":{"iopub.status.busy":"2025-03-19T14:20:25.827672Z","iopub.execute_input":"2025-03-19T14:20:25.827996Z","iopub.status.idle":"2025-03-19T14:20:25.832715Z","shell.execute_reply.started":"2025-03-19T14:20:25.827967Z","shell.execute_reply":"2025-03-19T14:20:25.831773Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"pip install --upgrade transformers\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T14:23:33.323585Z","iopub.execute_input":"2025-03-19T14:23:33.323929Z","iopub.status.idle":"2025-03-19T14:23:45.315888Z","shell.execute_reply.started":"2025-03-19T14:23:33.323899Z","shell.execute_reply":"2025-03-19T14:23:45.315037Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nCollecting transformers\n  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\nSuccessfully installed transformers-4.49.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Settings\nauthor_base_model = base_models[1]\nauthor_config_index = 1  # You can change this to select other configs\nrun_all_models = False  # Set True to run all models\n\n# Select configurations\nif author_config_index is not None:\n    selected_configurations = [configurations[author_config_index]]\nelse:\n    selected_configurations = configurations\n\n# Select base models\nselected_base_models = base_models if run_all_models else [author_base_model]\n\nmax_epochs = 20\npatience = 3\nresults = []\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Main Loop\nfor base_model in selected_base_models:\n    print(f\"Running for Base Model: {base_model}\")\n\n    # Special tokenizer handling if needed (e.g., ModernBERT)\n    tokenizer_args = {\"use_fast\": False} if \"ModernBERT\" in base_model else {}\n    tokenizer = AutoTokenizer.from_pretrained(base_model, **tokenizer_args)\n\n    # Preprocess data\n    input_ids, attention_masks, labels = preprocess_data(df, tokenizer)\n    dataset = TensorDataset(input_ids, attention_masks, labels)\n\n    # Data split\n    train_size = int(0.7 * len(dataset))\n    val_size = int(0.1 * len(dataset))\n    test_size = len(dataset) - train_size - val_size\n    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n\n    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n    val_dataloader = DataLoader(val_dataset, batch_size=16)\n    test_dataloader = DataLoader(test_dataset, batch_size=16)\n\n    # Config Loop\n    for config in selected_configurations:\n        print(f\"Running Configuration: {config}\")\n        model = EmotionModel(base_model_name=base_model, **config).to(device)\n        optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n        criterion = nn.CrossEntropyLoss()\n\n        best_val_loss = float(\"inf\")\n        patience_counter = 0\n\n        # Training Loop\n        for epoch in range(max_epochs):\n            print(f\"Epoch {epoch+1}/{max_epochs}\")\n            train_loss = train_model(model, train_dataloader, optimizer, criterion, device)\n            val_loss, _, _ = evaluate_model(model, val_dataloader, device)\n            print(f\"Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n\n            # Early Stopping\n            if val_loss < best_val_loss:\n                best_val_loss = val_loss\n                patience_counter = 0\n                torch.save(model.state_dict(), \"best_model.pt\")\n            else:\n                patience_counter += 1\n                if patience_counter >= patience:\n                    print(\"Early stopping triggered\")\n                    break\n\n        # Evaluation\n        model.load_state_dict(torch.load(\"best_model.pt\"))\n        _, test_preds, test_labels = evaluate_model(model, test_dataloader, device)\n        precision = precision_score(test_labels, test_preds, average='weighted')\n        recall = recall_score(test_labels, test_preds, average='weighted')\n        f1 = f1_score(test_labels, test_preds, average='weighted')\n        accuracy = accuracy_score(test_labels, test_preds)\n\n\n        # Collect results\n        results.append({\n            \"Base Model\": base_model,\n            \"Polynomial Attention\": config[\"use_poly_attention\"],\n            \"Mixout\": config[\"use_mixout\"],\n            \"LoRA\": config[\"use_lora\"],\n            \"BitFit\": config[\"use_bitfit\"],\n            \"ReFT\": config[\"use_reft\"],\n            \"Precision\": precision,\n            \"Recall\": recall,\n            \"F1-Score\": f1,\n            \"Accuracy\": accuracy\n        })\n\n# Show results\nresults_df = pd.DataFrame(results)\nprint(results_df)","metadata":{"id":"4RK7ZN6td0l7","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T10:08:55.768883Z","iopub.execute_input":"2025-03-17T10:08:55.769656Z","iopub.status.idle":"2025-03-17T12:48:33.589929Z","shell.execute_reply.started":"2025-03-17T10:08:55.769625Z","shell.execute_reply":"2025-03-17T12:48:33.588847Z"}},"outputs":[{"name":"stdout","text":"Running for Base Model: roberta-base\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Running Configuration: {'use_poly_attention': True, 'use_mixout': False, 'use_lora': True, 'use_bitfit': False, 'use_reft': True}\nEpoch 1/20\nTrain Loss: 0.8858, Validation Loss: 0.7670\nEpoch 2/20\nTrain Loss: 0.6822, Validation Loss: 0.6646\nEpoch 3/20\nTrain Loss: 0.6018, Validation Loss: 0.6143\nEpoch 4/20\nTrain Loss: 0.5245, Validation Loss: 0.5714\nEpoch 5/20\nTrain Loss: 0.4577, Validation Loss: 0.5599\nEpoch 6/20\nTrain Loss: 0.4150, Validation Loss: 0.5298\nEpoch 7/20\nTrain Loss: 0.3789, Validation Loss: 0.5566\nEpoch 8/20\nTrain Loss: 0.3442, Validation Loss: 0.5438\nEpoch 9/20\nTrain Loss: 0.3162, Validation Loss: 0.5674\nEarly stopping triggered\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-9-e3459c18bca4>:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"best_model.pt\"))\n","output_type":"stream"},{"name":"stdout","text":"     Base Model  Polynomial Attention  Mixout  LoRA  BitFit  ReFT  Precision  \\\n0  roberta-base                  True   False  True   False  True   0.812781   \n\n     Recall  F1-Score  Accuracy  \n0  0.808362  0.806469  0.808362  \n","output_type":"stream"}],"execution_count":9}]}